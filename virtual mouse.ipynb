{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import handtrackingModule as htm \n",
    "import time \n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from pynput.mouse import Controller, Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcam , hcam = 1280,720\n",
    "framered = 100\n",
    "smoothening = 7\n",
    "\n",
    "ptime = 0\n",
    "plocx, plocy = 0,0\n",
    "clocx, clocy = 0,0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,wcam)\n",
    "cap.set(4,hcam)\n",
    "detector = htm.handDetector(maxHands=1)\n",
    "mouse = Controller()\n",
    "wscreen, hscreen = mouse.screen_size if hasattr(mouse, 'screen_size') else (1920,1080)\n",
    "#wscreen , hscreen = pyautogui.size()\n",
    "\n",
    "while True:\n",
    "    #find hands landmarks\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    lmslist,bbox = detector.findPosition(img)\n",
    "        \n",
    "    # get the tip of the index and middle finger\n",
    "    if len(lmslist) != 0:\n",
    "        x1,y1 = lmslist[8][1:]\n",
    "        x2,y2 = lmslist[12][1:]\n",
    "        \n",
    "    #check which finger is up\n",
    "    fingers = detector.fingersUp()\n",
    "    cv2.rectangle(img,(framered,framered),(wcam-framered,hcam-framered),(255,0,0),2)\n",
    "    \n",
    "    #if only the index finger is up: moving mode\n",
    "    if len(fingers) > 1 and fingers[1] == 1 and fingers[2] == 0:\n",
    "        #convert coordinates\n",
    "        x3 = np.interp(x1,(0,wcam),(0,wscreen))\n",
    "        y3 = np.interp(y1,(framered,hcam-framered),(0,hscreen))\n",
    "        \n",
    "        #smooth values\n",
    "        clocx = plocx + (x3 - plocx) / smoothening\n",
    "        clocy = plocy + (y3 - plocy) / smoothening\n",
    "        \n",
    "        #move mouse \n",
    "        #pyautogui.moveTo(wscreen - clocx,clocy)\n",
    "        mouse.position = (wscreen - clocx,clocy)\n",
    "        cv2.circle(img,(x1,y1),15,(255,0,0),cv2.FILLED)\n",
    "        plocx, plocy = clocx, clocy\n",
    "    \n",
    "    # if both fingers are up: clicking mode\n",
    "    if len(fingers) > 1 and fingers[1] == 1 and fingers[2] == 1:\n",
    "        #find distance between fingers\n",
    "        length, img, lineinfo = detector.findDistance(8,12,img)\n",
    "        #click mouse if distance short\n",
    "        if length < 40:\n",
    "            cv2.circle(img,(lineinfo[4],lineinfo[5]),15,(255,0,0),cv2.FILLED)\n",
    "            #pyautogui.click()\n",
    "            mouse.click(Button.left, 1)\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        \n",
    "             \n",
    "\n",
    "    \n",
    "    ctime = time.time()\n",
    "    fps = 1/(ctime-ptime)\n",
    "    ptime = ctime\n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                    (255, 0, 0), 3)\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
